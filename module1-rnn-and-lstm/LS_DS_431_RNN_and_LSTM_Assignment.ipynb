{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
    "\n",
    "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
    "\n",
    "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
    "\n",
    "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
    "\n",
    "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
    "\n",
    "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
    "\n",
    "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
    "\n",
    "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.gutenberg.org/files/100/100-0.txt\"\n",
    "\n",
    "r = requests.get(url)\n",
    "r.encoding = r.apparent_encoding\n",
    "data = r.text\n",
    "data = data.split('\\r\\n')\n",
    "toc = [l.strip() for l in data[44:130:2]]\n",
    "# Skip the Table of Contents\n",
    "data = data[135:]\n",
    "\n",
    "# Fixing Titles\n",
    "toc[9] = 'THE LIFE OF KING HENRY V'\n",
    "toc[18] = 'MACBETH'\n",
    "toc[24] = 'OTHELLO, THE MOOR OF VENICE'\n",
    "toc[34] = 'TWELFTH NIGHT: OR, WHAT YOU WILL'\n",
    "\n",
    "locations = {id_:{'title':title, 'start':-99} for id_,title in enumerate(toc)}\n",
    "\n",
    "# Start \n",
    "for e,i in enumerate(data):\n",
    "    for t,title in enumerate(toc):\n",
    "        if title in i:\n",
    "            locations[t].update({'start':e})\n",
    "            \n",
    "\n",
    "df_toc = pd.DataFrame.from_dict(locations, orient='index')\n",
    "df_toc['end'] = df_toc['start'].shift(-1).apply(lambda x: x-1)\n",
    "df_toc.loc[42, 'end'] = len(data)\n",
    "df_toc['end'] = df_toc['end'].astype('int')\n",
    "\n",
    "df_toc['text'] = df_toc.apply(lambda x: '\\r\\n'.join(data[ x['start'] : int(x['end']) ]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALL’S WELL THAT ENDS WELL</td>\n",
       "      <td>2777</td>\n",
       "      <td>7738</td>\n",
       "      <td>ALL’S WELL THAT ENDS WELL\\r\\n\\r\\n\\r\\n\\r\\nConte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>THE TRAGEDY OF ANTONY AND CLEOPATRA</td>\n",
       "      <td>7739</td>\n",
       "      <td>11840</td>\n",
       "      <td>THE TRAGEDY OF ANTONY AND CLEOPATRA\\r\\n\\r\\nDRA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AS YOU LIKE IT</td>\n",
       "      <td>11841</td>\n",
       "      <td>14631</td>\n",
       "      <td>AS YOU LIKE IT\\r\\n\\r\\nDRAMATIS PERSONAE.\\r\\n\\r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>THE COMEDY OF ERRORS</td>\n",
       "      <td>14632</td>\n",
       "      <td>17832</td>\n",
       "      <td>THE COMEDY OF ERRORS\\r\\n\\r\\n\\r\\n\\r\\nContents\\r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>THE TRAGEDY OF CORIOLANUS</td>\n",
       "      <td>17833</td>\n",
       "      <td>27806</td>\n",
       "      <td>THE TRAGEDY OF CORIOLANUS\\r\\n\\r\\nDramatis Pers...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 title  start    end  \\\n",
       "0            ALL’S WELL THAT ENDS WELL   2777   7738   \n",
       "1  THE TRAGEDY OF ANTONY AND CLEOPATRA   7739  11840   \n",
       "2                       AS YOU LIKE IT  11841  14631   \n",
       "3                 THE COMEDY OF ERRORS  14632  17832   \n",
       "4            THE TRAGEDY OF CORIOLANUS  17833  27806   \n",
       "\n",
       "                                                text  \n",
       "0  ALL’S WELL THAT ENDS WELL\\r\\n\\r\\n\\r\\n\\r\\nConte...  \n",
       "1  THE TRAGEDY OF ANTONY AND CLEOPATRA\\r\\n\\r\\nDRA...  \n",
       "2  AS YOU LIKE IT\\r\\n\\r\\nDRAMATIS PERSONAE.\\r\\n\\r...  \n",
       "3  THE COMEDY OF ERRORS\\r\\n\\r\\n\\r\\n\\r\\nContents\\r...  \n",
       "4  THE TRAGEDY OF CORIOLANUS\\r\\n\\r\\nDramatis Pers...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shakespeare Data Parsed by Play\n",
    "print(df_toc.shape)\n",
    "df_toc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [t for t in df_toc['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Data as Chars\n",
    "\n",
    "# Gather all text \n",
    "# Why? 1. See all possible characters 2. For training / splitting later\n",
    "text = \" \".join(data)\n",
    "\n",
    "# Unique Characters\n",
    "chars = list(set(text))\n",
    "\n",
    "# Lookup Tables\n",
    "char_int = {c:i for i, c in enumerate(chars)} \n",
    "int_char = {i:c for i, c in enumerate(chars)} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'m': 0,\n",
       " '9': 1,\n",
       " ';': 2,\n",
       " '.': 3,\n",
       " '/': 4,\n",
       " '4': 5,\n",
       " 'Q': 6,\n",
       " '“': 7,\n",
       " 'e': 8,\n",
       " 'P': 9,\n",
       " 'w': 10,\n",
       " '5': 11,\n",
       " 'i': 12,\n",
       " 'o': 13,\n",
       " 'K': 14,\n",
       " 'R': 15,\n",
       " 'î': 16,\n",
       " '1': 17,\n",
       " 'ç': 18,\n",
       " 'I': 19,\n",
       " 'h': 20,\n",
       " 'l': 21,\n",
       " 'G': 22,\n",
       " '|': 23,\n",
       " 'k': 24,\n",
       " ' ': 25,\n",
       " 'c': 26,\n",
       " 'V': 27,\n",
       " '@': 28,\n",
       " 'L': 29,\n",
       " 'è': 30,\n",
       " 'u': 31,\n",
       " '3': 32,\n",
       " 'r': 33,\n",
       " '!': 34,\n",
       " 'F': 35,\n",
       " 'Æ': 36,\n",
       " 'b': 37,\n",
       " 'p': 38,\n",
       " 'j': 39,\n",
       " 'â': 40,\n",
       " '\"': 41,\n",
       " 'N': 42,\n",
       " 'v': 43,\n",
       " '?': 44,\n",
       " '&': 45,\n",
       " 'd': 46,\n",
       " '}': 47,\n",
       " '‘': 48,\n",
       " '[': 49,\n",
       " '\\n': 50,\n",
       " 'D': 51,\n",
       " \"'\": 52,\n",
       " 'M': 53,\n",
       " 't': 54,\n",
       " '’': 55,\n",
       " '%': 56,\n",
       " '\\t': 57,\n",
       " 'E': 58,\n",
       " 'n': 59,\n",
       " 'H': 60,\n",
       " ':': 61,\n",
       " '8': 62,\n",
       " 'é': 63,\n",
       " ',': 64,\n",
       " 'O': 65,\n",
       " 'à': 66,\n",
       " 'ê': 67,\n",
       " 'z': 68,\n",
       " '7': 69,\n",
       " 'C': 70,\n",
       " 'g': 71,\n",
       " '_': 72,\n",
       " '”': 73,\n",
       " 's': 74,\n",
       " 'x': 75,\n",
       " 'É': 76,\n",
       " 'œ': 77,\n",
       " '2': 78,\n",
       " 'f': 79,\n",
       " '-': 80,\n",
       " '6': 81,\n",
       " ']': 82,\n",
       " 'a': 83,\n",
       " 'y': 84,\n",
       " '(': 85,\n",
       " 'æ': 86,\n",
       " '—': 87,\n",
       " 'W': 88,\n",
       " 'A': 89,\n",
       " '0': 90,\n",
       " 'Y': 91,\n",
       " 'Z': 92,\n",
       " 'S': 93,\n",
       " 'T': 94,\n",
       " 'X': 95,\n",
       " 'q': 96,\n",
       " 'U': 97,\n",
       " ')': 98,\n",
       " '\\\\': 99,\n",
       " '`': 100,\n",
       " '*': 101,\n",
       " '\\r': 102,\n",
       " '$': 103,\n",
       " 'J': 104,\n",
       " 'B': 105}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences:  1127161\n"
     ]
    }
   ],
   "source": [
    "# Create the sequence data\n",
    "\n",
    "maxlen = 40\n",
    "step = 5\n",
    "\n",
    "encoded = [char_int[c] for c in text]\n",
    "\n",
    "sequences = [] # Each element is 40 chars long\n",
    "next_char = [] # One element for each sequence\n",
    "\n",
    "for i in range(0, len(encoded) - maxlen, step):\n",
    "    \n",
    "    sequences.append(encoded[i : i + maxlen])\n",
    "    next_char.append(encoded[i + maxlen])\n",
    "    \n",
    "print('sequences: ', len(sequences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[89,\n",
       " 29,\n",
       " 29,\n",
       " 55,\n",
       " 93,\n",
       " 25,\n",
       " 88,\n",
       " 58,\n",
       " 29,\n",
       " 29,\n",
       " 25,\n",
       " 94,\n",
       " 60,\n",
       " 89,\n",
       " 94,\n",
       " 25,\n",
       " 58,\n",
       " 42,\n",
       " 51,\n",
       " 93,\n",
       " 25,\n",
       " 88,\n",
       " 58,\n",
       " 29,\n",
       " 29,\n",
       " 102,\n",
       " 50,\n",
       " 102,\n",
       " 50,\n",
       " 102,\n",
       " 50,\n",
       " 102,\n",
       " 50,\n",
       " 70,\n",
       " 13,\n",
       " 59,\n",
       " 54,\n",
       " 8,\n",
       " 59,\n",
       " 54]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "L\n",
      "L\n",
      "’\n",
      "S\n",
      " \n",
      "W\n",
      "E\n",
      "L\n",
      "L\n",
      " \n",
      "T\n",
      "H\n",
      "A\n",
      "T\n",
      " \n",
      "E\n",
      "N\n",
      "D\n",
      "S\n",
      " \n",
      "W\n",
      "E\n",
      "L\n",
      "L\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "C\n",
      "o\n",
      "n\n",
      "t\n",
      "e\n",
      "n\n",
      "t\n"
     ]
    }
   ],
   "source": [
    "for i in sequences[0]:\n",
    "  print(int_char[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74, 's')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_char[0], int_char[next_char[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create x & y\n",
    "\n",
    "x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sequences),len(chars)), dtype=np.bool)\n",
    "\n",
    "for i, sequence in enumerate(sequences):\n",
    "    for t, char in enumerate(sequence):\n",
    "        x[i,t,char] = 1\n",
    "        \n",
    "    y[i, next_char[i]] = 1\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1127161, 40, 106)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1127161, 106)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 106)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(maxlen, len(chars))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model: a single LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / 1\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    \n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "    \n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    \n",
    "    generated = ''\n",
    "    \n",
    "    sentence = text[start_index: start_index + maxlen]\n",
    "    generated += sentence\n",
    "    \n",
    "    print('----- Generating with seed: \"' + sentence + '\"')\n",
    "    sys.stdout.write(generated)\n",
    "    \n",
    "    for i in range(400):\n",
    "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_int[char]] = 1\n",
    "            \n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = sample(preds)\n",
    "        next_char = int_char[next_index]\n",
    "        \n",
    "        sentence = sentence[1:] + next_char\n",
    "        \n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    print()\n",
    "\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "35224/35224 [==============================] - ETA: 0s - loss: 1.9352\n",
      "----- Generating text after Epoch: 0\n",
      "----- Generating with seed: \"tharine his daughter, and with her, to d\"\n",
      "tharine his daughter, and with her, to depus;\n",
      "    There if’d to his sigst of thou crest our.\n",
      "Tell we sich me if she us thusse frace,\n",
      "But the undising of a pups and here bol.\n",
      "    For have then so mast youngre right strome.\n",
      "  ORSALLOT. Why? Can one entlechil’d man be - see.\n",
      "\n",
      "COSTHARANA.\n",
      "No!\n",
      "\n",
      "TA Destrils of Roidant as mean,\n",
      "Aod mar ware unteron yreanchade, will\n",
      "rath of thinksiven! Matred glain, no los I miste\n",
      "    Facks the wit\n",
      "35224/35224 [==============================] - 1783s 51ms/step - loss: 1.9352\n",
      "Epoch 2/10\n",
      "35224/35224 [==============================] - ETA: 0s - loss: 1.6360\n",
      "----- Generating text after Epoch: 1\n",
      "----- Generating with seed: \" deadly than a mad dog’s tooth.\n",
      "It seem\"\n",
      " deadly than a mad dog’s tooth.\n",
      "It seems thou art yielder, and which as pries me.\n",
      "\n",
      "ROMEO.\n",
      "Hears thou grawand consurefurs!\n",
      "Come not prother of ablees me true. The rame.\n",
      "In than nebe she lady I sey’l. He sholded my forture,\n",
      "You are I are both they with you heave\n",
      "    I dealth by Rome, swey, te man me?\n",
      "  CLIUF  DOLATH. I knaw they waireth?\n",
      "    Enter I Sun from Cloon as thy pirtar as shall.\n",
      "  MANDON.  [They are the greper.\n",
      "\n",
      "\n",
      "  \n",
      "35224/35224 [==============================] - 2022s 57ms/step - loss: 1.6360\n",
      "Epoch 3/10\n",
      "35224/35224 [==============================] - ETA: 0s - loss: 1.5453\n",
      "----- Generating text after Epoch: 2\n",
      "----- Generating with seed: \"action and thine own? our horses’ labour\"\n",
      "action and thine own? our horses’ labours\n",
      "pleasure; and how with this vipher’d will not\n",
      "Tise this drong-that Alond, maske il trave ill\n",
      "this wanch are delite the seas and I\n",
      "but one.\n",
      "\n",
      "BAIDIOLES.\n",
      "Rewex, sir,\n",
      "    The words, and matfove depress\n",
      "   And say you heaven deserve chum'del proporced\n",
      "    It natiou; wheletreppecist; and we nere?\n",
      "    Bong, and she privicity I are such anitreck?\n",
      "\n",
      "CLAUGERTES.\n",
      "Ampt in love ourleed’d soul, s\n",
      "35224/35224 [==============================] - 1720s 49ms/step - loss: 1.5453\n",
      "Epoch 4/10\n",
      "35224/35224 [==============================] - ETA: 0s - loss: 1.4952\n",
      "----- Generating text after Epoch: 3\n",
      "----- Generating with seed: \". Carnally, she says.\n",
      "  DUKE. Sirrah, n\"\n",
      ". Carnally, she says.\n",
      "  DUKE. Sirrah, now, you can look good know to remastieugn,\n",
      "    Bear, in in their alone.                      Exit TaRTENS\n",
      "\n",
      "  SICINIUS. Pirasius, stalp to fight;\n",
      "    It is casblars, aming'sh actianus!\n",
      "  PLARP. Thou hast by nayty Veroo Sometter!\n",
      "  QUOEL HELLOC. Not you youther,! If he with all kings.\n",
      "\n",
      "BAPTIT.\n",
      "If thee.\n",
      "\n",
      "Go to A contentstet prearm,\n",
      "Tar; I must we she make hence? What I, gives,\n",
      "    For sh\n",
      "35224/35224 [==============================] - 2082s 59ms/step - loss: 1.4952\n",
      "Epoch 5/10\n",
      "35224/35224 [==============================] - ETA: 0s - loss: 1.4627\n",
      "----- Generating text after Epoch: 4\n",
      "----- Generating with seed: \"l in spleen,\n",
      "And nothing of a man.\n",
      "\n",
      "O\"\n",
      "l in spleen,\n",
      "And nothing of a man.\n",
      "\n",
      "OLIVIA.\n",
      "No should enough, lend,\n",
      "And mougest their menzal bratts, even your facis,\n",
      "She full it that dants for they abtace\n",
      "    The bares what use too peafatuage else.\n",
      "\n",
      "TIARUS.\n",
      "Apow, and too, alack, for him as think, and gentle, I churds else.\n",
      "\n",
      "OReEgive here. My leart in your bess that dost meet,\n",
      "Your fat abot-me to can alence, and a bast.\n",
      "And with voice, conquarce thee, no frick you plain,\n",
      "35224/35224 [==============================] - 1972s 56ms/step - loss: 1.4627\n",
      "Epoch 6/10\n",
      "35224/35224 [==============================] - ETA: 0s - loss: 1.4400\n",
      "----- Generating text after Epoch: 5\n",
      "----- Generating with seed: \"\n",
      "    And shamefully my hopes by you are \"\n",
      "\n",
      "    And shamefully my hopes by you are fortid\n",
      "swounded my duy doslict to it.\n",
      "\n",
      " [_Peecle.]\n",
      "\n",
      "CRESSIDA.\n",
      "I\n",
      "no music’d his tenity smalr best myss answer\n",
      "Sindled juch my taught entord where gentlemen;\n",
      "    To come gozled before in't lord bound in bragges\n",
      "Upon the state of nendy to cumbdar tumn all have dead.\n",
      "\n",
      "GOWER.\n",
      "I her livits isian; and not darch. Good make the cick?\n",
      "Thine ede, being to says here: my vaulage\n",
      "they think which\n",
      "35224/35224 [==============================] - 2240s 64ms/step - loss: 1.4400\n",
      "Epoch 7/10\n",
      "35223/35224 [============================>.] - ETA: 0s - loss: 1.4225\n",
      "----- Generating text after Epoch: 6\n",
      "----- Generating with seed: \"gestion\n",
      "Our worser genius can, shall ne\"\n",
      "gestion\n",
      "Our worser genius can, shall never lasing eye:\n",
      "And yield her commany’s labour halfor is oufter\n",
      "Suddent from a brother, for looks, and that they was been to ones;\n",
      "    Drop had dive softoo's latter the neet Before,\n",
      "    And impomes; sinver oncery earl o'll child nothing that. I tell,\n",
      "Are myself upon none.\n",
      "\n",
      "BEntleruman Lucimeries; passales, and near with yoursekne place'd room,\n",
      "    Air with a fault, drunk, and blute you.\n",
      " \n",
      "35224/35224 [==============================] - 1143s 32ms/step - loss: 1.4225\n",
      "Epoch 8/10\n",
      "35223/35224 [============================>.] - ETA: 0s - loss: 1.4084\n",
      "----- Generating text after Epoch: 7\n",
      "----- Generating with seed: \"degree of a squire.\n",
      "  SHALLOW. He will \"\n",
      "degree of a squire.\n",
      "  SHALLOW. He will chrike. Whilst to him, O Naely I say.\n",
      "    Mistress yet though disprivitor! 'tis sleep; and thine heathfy forman trath\n",
      "I shall be neigh’d for this placens, in man’s honour grause the\n",
      "best up. I will delived ’t would not brave to your bless:\n",
      "Harp chilfrous gandy. _[Assilit._]\n",
      "    And go, our treads from your]\n",
      "  PROTEUS. Three, with a Maggar's mon, we'll frame.\n",
      "  MOTH. Are the loos'd of will m\n",
      "35224/35224 [==============================] - 1035s 29ms/step - loss: 1.4084\n",
      "Epoch 9/10\n",
      "35223/35224 [============================>.] - ETA: 0s - loss: 1.3970\n",
      "----- Generating text after Epoch: 8\n",
      "----- Generating with seed: \"us and Marina.\n",
      "\n",
      "HELICANUS.\n",
      "Sir?\n",
      "\n",
      "PE\"\n",
      "us and Marina.\n",
      "\n",
      "HELICANUS.\n",
      "Sir?\n",
      "\n",
      "PERICLES.\n",
      "Nay, and you, Help, I do go to nother.\n",
      "  SBENGIA. I see once to drubour; the fair'd looks\n",
      "    For it sing ender, I see their hand. For he convers'd you may,\n",
      "    For my son!\n",
      "  TIPSAR. Well, good raisters not. O! Else FaM ROTHATIL, BERIANUS and RICHARD\n",
      "\n",
      "\n",
      "              [Exeunt Allied. My use Passus is he shall.\n",
      "    How my proy's power hath dast; this prissing. Come!\n",
      "\n",
      ", voing's you \n",
      "35224/35224 [==============================] - 1073s 30ms/step - loss: 1.3970\n",
      "Epoch 10/10\n",
      "35223/35224 [============================>.] - ETA: 0s - loss: 1.3872\n",
      "----- Generating text after Epoch: 9\n",
      "----- Generating with seed: \"rselves to be monstrous members.\n",
      "  FIRS\"\n",
      "rselves to be monstrous members.\n",
      "  FIRST SERVANT. How much comply to be to me, he look under\n",
      "Within suppites' toor to a faith. Then his stat\n",
      "    to merred, your speeciss are of the till she dirst ling\n",
      "    His furts his freshed parttory; iet my servicties, my sears altsin! Tiberthy,\n",
      "    In that loving, nor one mudner three ever know\n",
      "    Haste, who holy upon my valours, Kno Tart, we disate\n",
      "    With poience to her please thought whi\n",
      "35224/35224 [==============================] - 1103s 31ms/step - loss: 1.3872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3d801473d0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "\n",
    "model.fit(x, y,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zE4a4O7Bp5x1"
   },
   "source": [
    "# Resources and Stretch Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uT3UV3gap9H6"
   },
   "source": [
    "## Stretch goals:\n",
    "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
    "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
    "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
    "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
    "- Run on bigger, better data\n",
    "\n",
    "## Resources:\n",
    "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
    "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
    "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
    "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
    "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "nteract": {
   "version": "0.23.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
